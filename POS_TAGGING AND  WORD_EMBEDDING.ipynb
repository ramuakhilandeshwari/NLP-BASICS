{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMSc9T6LPSMs"
   },
   "source": [
    "<center><h2>Program for POS Tagging and Word Embeddings.</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6tjntwfeNqQ"
   },
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57ejvxrlPDI4"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LEuzFp5ve1ul"
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "nltk.download( 'averaged_perceptron_tagger')\n",
    "nltk.download( 'tagsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JyQVHNLdj1M"
   },
   "source": [
    "# POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1636038514955,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "Yu6kWZw7e5Dm",
    "outputId": "16f1b8f5-dd9c-4763-a1ea-07103e3c03dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts of Speech (POS) Tags are: \n",
      "[('Ramoji', 'NNP'), ('Film', 'NNP'), ('City', 'NNP'), ('.', '.'), ('Ramoji', 'NNP'), ('Film', 'NNP'), ('City', 'NNP'), ('is', 'VBZ'), ('India', 'NNP'), ('’', 'NNP'), ('s', 'VBZ'), ('only', 'RB'), ('thematic', 'JJ'), ('holiday', 'NN'), ('destination', 'NN'), ('with', 'IN'), ('cine-magic', 'JJ'), ('.', '.'), ('Certified', 'VBN'), ('as', 'IN'), ('the', 'DT'), ('World', 'NNP'), ('’', 'NNP'), ('s', 'RB'), ('Largest', 'NNP'), ('Film', 'NNP'), ('Studio', 'NNP'), ('complex', 'NN'), ('by', 'IN'), ('Guinness', 'NNP'), ('World', 'NNP'), ('Records', 'NNP'), (',', ','), ('it', 'PRP'), ('spreads', 'VBZ'), ('across', 'IN'), ('2000', 'CD'), ('acres', 'NNS'), ('.', '.'), ('Millions', 'NNS'), ('of', 'IN'), ('tourists', 'NNS'), ('visit', 'VBP'), ('the', 'DT'), ('amusement', 'NN'), ('park', 'NN'), ('to', 'TO'), ('live', 'VB'), ('their', 'PRP$'), ('dream', 'NN'), ('vacation', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Using nltk.pos_tag\n",
    "text = 'Ramoji Film City. Ramoji Film City is India’s only thematic holiday destination with cine-magic. \\\n",
    "Certified as the World’s Largest Film Studio complex by Guinness World Records,\\\n",
    "it spreads across 2000 acres. Millions of tourists visit the amusement park to live their dream vacation.'\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(f'Parts of Speech (POS) Tags are: \\n{nltk.pos_tag(tokens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1636038652361,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "7x_inbr7f44c",
    "outputId": "296801b6-5559-437f-ba13-d124aa880188"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('today', 'NN'),\n",
       " ('is', 'PRP'),\n",
       " ('a', 'PRP'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('day', 'NN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Averaged Perceptron tagger\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "tagger = PerceptronTagger(load=False)\n",
    "tagger.train([[('today','NN'),('is','VBZ'),('good','JJ'),('day','NN')],[('yes','NNS'),('it','PRP'),('beautiful','JJ')]])\n",
    "\n",
    "tagger.tag(['today','is','a','beautiful','day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1636038724736,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "mEh0jQ2WgZj3",
    "outputId": "334e3a56-2d04-449a-89f1-53901f6fa86d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Percepton tagger\n",
    "pretrain = PerceptronTagger()\n",
    "tag1 = pretrain.tag('The quick brown fox jumps over the lazy dog'.split())\n",
    "print(tag1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2333,
     "status": "ok",
     "timestamp": 1636038970696,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "LsW1Yk9ZhLPG",
    "outputId": "0660d39e-46a5-4085-88b3-0f7b6943c602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     POS    TAG    Dep    POS explained        tag explained \n",
      "Ramoji   PROPN  NNP    compound proper noun          noun, proper singular\n",
      "Film     PROPN  NNP    compound proper noun          noun, proper singular\n",
      "City     PROPN  NNP    ROOT   proper noun          noun, proper singular\n",
      ".        PUNCT  .      punct  punctuation          punctuation mark, sentence closer\n",
      "Ramoji   PROPN  NNP    compound proper noun          noun, proper singular\n",
      "Film     PROPN  NNP    compound proper noun          noun, proper singular\n",
      "City     PROPN  NNP    nsubj  proper noun          noun, proper singular\n",
      "is       AUX    VBZ    ROOT   auxiliary            verb, 3rd person singular present\n",
      "India    PROPN  NNP    attr   proper noun          noun, proper singular\n",
      "’s       PART   POS    punct  particle             possessive ending\n",
      "only     ADJ    JJ     advmod adjective            adjective\n",
      "thematic ADJ    JJ     amod   adjective            adjective\n",
      "holiday  NOUN   NN     compound noun                 noun, singular or mass\n",
      "destination NOUN   NN     attr   noun                 noun, singular or mass\n",
      "with     ADP    IN     prep   adposition           conjunction, subordinating or preposition\n",
      "cine     ADJ    JJ     compound adjective            adjective\n",
      "-        PUNCT  HYPH   punct  punctuation          punctuation mark, hyphen\n",
      "magic    NOUN   NN     pobj   noun                 noun, singular or mass\n",
      ".        PUNCT  .      punct  punctuation          punctuation mark, sentence closer\n",
      "Certified VERB   VBN    advcl  verb                 verb, past participle\n",
      "as       SCONJ  IN     prep   subordinating conjunction conjunction, subordinating or preposition\n",
      "the      DET    DT     det    determiner           determiner\n",
      "World    PROPN  NNP    nmod   proper noun          noun, proper singular\n",
      "’s       PART   POS    punct  particle             possessive ending\n",
      "Largest  PROPN  NNP    compound proper noun          noun, proper singular\n",
      "Film     PROPN  NNP    compound proper noun          noun, proper singular\n",
      "Studio   PROPN  NNP    compound proper noun          noun, proper singular\n",
      "complex  ADJ    JJ     pobj   adjective            adjective\n",
      "by       ADP    IN     prep   adposition           conjunction, subordinating or preposition\n",
      "Guinness PROPN  NNP    compound proper noun          noun, proper singular\n",
      "World    PROPN  NNP    compound proper noun          noun, proper singular\n",
      "Records  PROPN  NNPS   pobj   proper noun          noun, proper plural\n",
      ",        PUNCT  ,      punct  punctuation          punctuation mark, comma\n",
      "it       PRON   PRP    nsubj  pronoun              pronoun, personal\n",
      "spreads  VERB   VBZ    ROOT   verb                 verb, 3rd person singular present\n",
      "across   ADP    IN     prep   adposition           conjunction, subordinating or preposition\n",
      "2000     NUM    CD     nummod numeral              cardinal number\n",
      "acres    NOUN   NNS    pobj   noun                 noun, plural\n",
      ".        PUNCT  .      punct  punctuation          punctuation mark, sentence closer\n",
      "Millions NOUN   NNS    nsubj  noun                 noun, plural\n",
      "of       ADP    IN     prep   adposition           conjunction, subordinating or preposition\n",
      "tourists NOUN   NNS    pobj   noun                 noun, plural\n",
      "visit    VERB   VBP    ROOT   verb                 verb, non-3rd person singular present\n",
      "the      DET    DT     det    determiner           determiner\n",
      "amusement NOUN   NN     compound noun                 noun, singular or mass\n",
      "park     NOUN   NN     dobj   noun                 noun, singular or mass\n",
      "to       PART   TO     aux    particle             infinitival \"to\"\n",
      "live     VERB   VB     advcl  verb                 verb, base form\n",
      "their    DET    PRP$   poss   determiner           pronoun, possessive\n",
      "dream    NOUN   NN     compound noun                 noun, singular or mass\n",
      "vacation NOUN   NN     dobj   noun                 noun, singular or mass\n",
      ".        PUNCT  .      punct  punctuation          punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "# Using Spacy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text= 'Ramoji Film City. Ramoji Film City is India’s only thematic holiday destination with cine-magic. \\\n",
    "Certified as the World’s Largest Film Studio complex by Guinness World Records,\\\n",
    "it spreads across 2000 acres. Millions of tourists visit the amusement park to live their dream vacation.'\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "print(f\"{'text':{8}} {'POS':{6}} {'TAG':{6}} {'Dep':{6}} {'POS explained':{20}} {'tag explained'} \")\n",
    "\n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text:{8}} {token.pos_:{6}} {token.tag_:{6}} {token.dep_:{6}} {spacy.explain(token.pos_):{20}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJA7q8qMdoHz"
   },
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFvT-5vxk2Bu"
   },
   "source": [
    "## Genism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4803,
     "status": "ok",
     "timestamp": 1636039344738,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "1oV7Y17pdsgM",
    "outputId": "d07b97b5-64b7-4c4d-f2b8-547fe25cc718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1636039676022,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "bE5twpzBj-N5",
    "outputId": "876ef12e-953a-4b09-a0a9-4f088f04a2c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=common_texts,  window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1636039727889,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "luZmjvLYkQu0",
    "outputId": "ef2a5a7e-e31d-4be0-c2f3-728052680566"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "model.train([[\"hello\", \"world\"]], total_examples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1636039781702,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "YCQWi7cMkZpr",
    "outputId": "e559892f-9627-40c6-c00a-dfc76d298cf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user', 0.20155365765094757),\n",
       " ('human', 0.10132145881652832),\n",
       " ('graph', 0.07621297240257263),\n",
       " ('response', 0.07165258377790451),\n",
       " ('trees', 0.02122265100479126),\n",
       " ('survey', 0.010687898844480515),\n",
       " ('eps', -0.03111916035413742),\n",
       " ('minors', -0.05052899569272995),\n",
       " ('interface', -0.05236271023750305),\n",
       " ('system', -0.06287829577922821)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model.wv['computer']  # get numpy vector of a word\n",
    "sims = model.wv.most_similar('computer', topn=10)  # get other similar words\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1636040063569,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "zVE0WpPzlhrs"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1636040073446,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "jgMTTeGyllYh",
    "outputId": "cb7d71ba-3d9a-4bf9-db22-4a53ac2a6e0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "# Show all available models in gensim-data\n",
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1636040536133,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "W52L9-aMnQXE"
   },
   "outputs": [],
   "source": [
    "# Uploading file and processing \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "  \n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "  \n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1636040602495,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "0Ya-ey3imCtq",
    "outputId": "92e7d564-2ed7-4172-a1f0-7d14acb3f4be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'alice' and 'wonderland' - CBOW :  0.008664893\n"
     ]
    }
   ],
   "source": [
    "# Continuous Bag-of-Word Model (CBOW)\n",
    "sample = open(\"/content/charminar.txt\", \"r\")\n",
    "s = sample.read()\n",
    "  \n",
    "  \n",
    "# Replaces escape character with space\n",
    "f = s.replace(\"\\n\", \" \")\n",
    "  \n",
    "data = []\n",
    "  \n",
    "# iterate through each sentence in the file\n",
    "for i in sent_tokenize(f):\n",
    "    temp = []\n",
    "      \n",
    "    # tokenize the sentence into words\n",
    "    for j in word_tokenize(i):\n",
    "        temp.append(j.lower())\n",
    "  \n",
    "    data.append(temp)\n",
    "  \n",
    "# Create CBOW model\n",
    "model1 = gensim.models.Word2Vec(data, min_count = 1, \n",
    "                              size = 100, window = 5)\n",
    "  \n",
    "# Print results\n",
    "print(\"Cosine similarity between 'Charminar' \" + \n",
    "               \"and 'Golcanda' - CBOW : \",\n",
    "    model1.similarity('charminar', 'golconda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1636040709727,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "OJZeJRD1n58o",
    "outputId": "04916b4a-c59a-49c1-8258-3d9cc6e9d03e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'Charminar' and 'Golcanda' - CBOW :  0.017693968\n"
     ]
    }
   ],
   "source": [
    "# Skip-Gram Model\n",
    "model2 = gensim.models.Word2Vec(data, min_count = 1, size = 100,\n",
    "                                             window = 5, sg = 1)\n",
    "  \n",
    "# Print results\n",
    "print(\"Cosine similarity between 'Charminar' \" + \n",
    "               \"and 'Golcanda' - CBOW : \",\n",
    "    model2.similarity('charminar', 'golconda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ir0KGWpOo_o7"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EB2s9USoIbS"
   },
   "source": [
    "<h2> The skip gram is showing higher similarity than CBOW. Moreover, we can define our own models and refine it based on the requirement. In the POS tagging using percepton tagger we can chaange the POS of word. Using genism, we can find the different context of the given word. </h2>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM7TI/koU0/OcviaIdhI0Db",
   "name": "2048046_LAB9.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
