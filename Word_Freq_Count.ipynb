{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRjwekR75f8C"
   },
   "source": [
    "<CENTER> <B> <U> WORD FFREQUENCY COUNT & REMOVING STOP WORDS </CENTER> </B> </U>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFsOHJiSG4CE"
   },
   "source": [
    "# Simple FreqDist() for counting word frequency without eliminating stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1628865260835,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "cu7gy8Ti5Tgl",
    "outputId": "f1935aae-685d-4313-bc16-68168d6d4f15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 2), ('son', 2), ('she', 2), ('Hi,', 1), ('Hello,', 1), ('this', 1), ('is', 1), ('mike,', 1), ('saw', 1), ('your', 1), ('playing', 1), ('in', 1), ('the', 1), ('garden.Besides', 1), ('that,', 1), ('sometimes', 1), ('my', 1), ('studies', 1), ('math', 1), ('for', 1), ('fun.', 1), ('cannot', 1), ('believe', 1), ('said', 1), ('that.', 1), ('always', 1), ('says', 1), ('such', 1), ('things', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Importing nltk and downloading the data\n",
    "import nltk\n",
    "nltk.download('all')\n",
    "\n",
    "# Count and display how often a word occurs in a text and plot the same\n",
    "txt=\"Hi, Hello, this is mike, I saw your son playing in the garden.Besides that, sometimes my son studies math for fun. I cannot believe she said that. she always says such things\"\n",
    "data = txt.split(' ')\n",
    "fdist1 = nltk.FreqDist(data)\n",
    "print (fdist1.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFdIzO5iHGQj"
   },
   "source": [
    "# Accesing the single txt document and saving the word count freq in excel after eliminating the stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 3524,
     "status": "ok",
     "timestamp": 1628867704639,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "JSv-cwxx88i2",
    "outputId": "75f7d5e7-cd83-483c-f548-3bf6763da9da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15th</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815_</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zing</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwilliam</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzling</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8436 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Frequency\n",
       "000               1\n",
       "1500              1\n",
       "15th              1\n",
       "1813              3\n",
       "1815_             1\n",
       "...             ...\n",
       "zing              1\n",
       "zip               3\n",
       "zwilliam          2\n",
       "zzling            1\n",
       "zzy               1\n",
       "\n",
       "[8436 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing the text document from web and counting the word frequency\n",
    "# This is specifically for one document\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Download the book\n",
    "response = requests.get('http://www.gutenberg.org/cache/epub/42671/pg42671.txt')\n",
    "\n",
    "# Converting the data to series frame to fit the CountVectorizer \n",
    "s=pd.Series(response)\n",
    "\n",
    "\n",
    "word_vectorizer = CountVectorizer(ngram_range=(1,1), \n",
    "                                  analyzer='word', \n",
    "                                  stop_words='english')\n",
    "sparse_matrix = word_vectorizer.fit_transform(s)\n",
    "w_freq = sum(sparse_matrix).toarray()[0]\n",
    "w_df=pd.DataFrame(w_freq, \n",
    "                  index=word_vectorizer.get_feature_names(), \n",
    "                  columns=['Frequency'])\n",
    "\n",
    "w_df.to_excel('Word_Count_Freq.xlsx')\n",
    "w_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4YYisClHpea"
   },
   "source": [
    "# Accesing the multiple txt document and saving the word count freq in excel after eliminating the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "executionInfo": {
     "elapsed": 5502,
     "status": "ok",
     "timestamp": 1628868069971,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "kpjiUP3cFvuG",
    "outputId": "a08281d1-4b8b-491c-d72c-f27b6681163d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>10_th</th>\n",
       "      <th>11</th>\n",
       "      <th>11th</th>\n",
       "      <th>12</th>\n",
       "      <th>12th</th>\n",
       "      <th>13</th>\n",
       "      <th>13th</th>\n",
       "      <th>14</th>\n",
       "      <th>1400</th>\n",
       "      <th>14th</th>\n",
       "      <th>15</th>\n",
       "      <th>1500</th>\n",
       "      <th>15th</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>17â</th>\n",
       "      <th>18</th>\n",
       "      <th>1813</th>\n",
       "      <th>1815_</th>\n",
       "      <th>1867</th>\n",
       "      <th>1887</th>\n",
       "      <th>18th</th>\n",
       "      <th>18â</th>\n",
       "      <th>19</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1998</th>\n",
       "      <th>19th</th>\n",
       "      <th>20</th>\n",
       "      <th>2001</th>\n",
       "      <th>2013</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>26</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yearned</th>\n",
       "      <th>years</th>\n",
       "      <th>yearsâ</th>\n",
       "      <th>yell</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yellower</th>\n",
       "      <th>yelping</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yesterdayâ</th>\n",
       "      <th>yesternightâ</th>\n",
       "      <th>yesâ</th>\n",
       "      <th>yetâ</th>\n",
       "      <th>yield</th>\n",
       "      <th>yielded</th>\n",
       "      <th>yielding</th>\n",
       "      <th>yon</th>\n",
       "      <th>yonder</th>\n",
       "      <th>yore</th>\n",
       "      <th>york</th>\n",
       "      <th>yorkshire</th>\n",
       "      <th>young</th>\n",
       "      <th>younge</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youngster</th>\n",
       "      <th>yourn</th>\n",
       "      <th>yourselfâ</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>youthfulness</th>\n",
       "      <th>youths</th>\n",
       "      <th>youthâ</th>\n",
       "      <th>youâ</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zest</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pride and Prejudice</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frankenstein</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Jekyll and Mr. Hyde</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Great Expectations</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 16253 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         000  10  10_th  11  ...  zeal  zealous  zest  zip\n",
       "name                                         ...                          \n",
       "Pride and Prejudice        1   0      0   0  ...     0        0     0    3\n",
       "Frankenstein               1   2      0   2  ...     4        0     0    1\n",
       "Dr. Jekyll and Mr. Hyde    1   0      1   0  ...     0        0     0    1\n",
       "Great Expectations         1   0      0   0  ...     2        2     1    0\n",
       "\n",
       "[4 rows x 16253 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing the text document from web and counting the word frequency\n",
    "# This is for one multiple document\n",
    "\n",
    "\n",
    "# Build our dataframe\n",
    "df = pd.DataFrame([\n",
    "    { 'name': 'Pride and Prejudice', 'url': 'http://www.gutenberg.org/cache/epub/42671/pg42671.txt' },\n",
    "    { 'name': 'Frankenstein', 'url': 'https://www.gutenberg.org/files/84/84-0.txt' },\n",
    "    { 'name': 'Dr. Jekyll and Mr. Hyde', 'url': 'https://www.gutenberg.org/files/43/43-0.txt' },\n",
    "    { 'name': 'Great Expectations', 'url': 'https://www.gutenberg.org/files/1400/1400-0.txt' },\n",
    "])\n",
    "\n",
    "# Download the contents of the book, put it in the 'content' column\n",
    "df['content'] = df.url.apply(lambda url: requests.get(url).text)\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), \n",
    "                                  analyzer='word', \n",
    "                                  stop_words='english')\n",
    "\n",
    "# Use the content column instead of our single text variable\n",
    "matrix = vectorizer.fit_transform(df.content)\n",
    "counts = pd.DataFrame(matrix.toarray(),\n",
    "                  index=df.name,\n",
    "                  columns=vectorizer.get_feature_names())\n",
    "counts.to_excel('Multiple_Text_File_Conversion.xlsx')\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykS73AIDHuMZ"
   },
   "source": [
    "# freq_count extracter that accept the textfile and prints the frequency word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1628869108588,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "lqZQ--51-Y_h"
   },
   "outputs": [],
   "source": [
    "def freq_count(txt_file):\n",
    "  # Program will display a welcome message to the user\n",
    "  print(\"Welcome! This program will analyze your file to provide a word count, the top 30 words and remove the following stopwords.\\n\")\n",
    "  print('='*120,'\\n')\n",
    "  s = open(txt_file,'r').read()  # Open the input file\n",
    "\n",
    "  # Program will count the characters in text file\n",
    "  num_chars = len(s)\n",
    "\n",
    "  # Program will count the lines in the text file\n",
    "  num_lines = s.count('\\n')\n",
    "\n",
    "  # Converting to lowercase\n",
    "  sl=s.lower()\n",
    "\n",
    "  # Program will call split with no arguments\n",
    "  words = sl.split()\n",
    "  d = {}\n",
    "  for w in words:\n",
    "      if w in d:\n",
    "          d[w] += 1\n",
    "      else:\n",
    "          d[w] = 1\n",
    "\n",
    "  num_words = sum(d[w] for w in d)\n",
    "\n",
    "  lst = [(d[w],w) for w in d]\n",
    "  lst.sort()\n",
    "  lst.reverse()\n",
    "  \n",
    "  stop_words = set(stopwords.words('english')) # creating a set makes the searching faster\n",
    "  print ([word for word in lst if word not in stop_words])\n",
    "  print('='*120,'\\n')\n",
    "\n",
    "  # Program will print the results\n",
    "  print('Your input file has characters = '+str(num_chars))\n",
    "  print('Your input file has lines = '+str(num_lines))\n",
    "  print('Your input file has the following words = '+str(num_words))\n",
    "  print('='*120,'\\n\\n')\n",
    "  print('\\n The 30 most frequent words are /n')\n",
    "\n",
    "  i = 1\n",
    "  for count, word in lst[:30]:\n",
    "    print('%2s. %4s %s' %(i,count,word))\n",
    "    i+= 1\n",
    "\n",
    "  print('='*80,'\\n\\n')\n",
    "  print('@'*50,\"\\tThank You!\\t\",'@'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1628869114002,
     "user": {
      "displayName": "R AKHILANDESHWARI 2048046",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIkCurCgc78Nn4rfHenbXpNzRwE23THtku9QZFlQ=s64",
      "userId": "00252764270953512856"
     },
     "user_tz": -330
    },
    "id": "IfvbiZBVIk5b",
    "outputId": "38471bbf-5f47-4b88-caae-9783b36a9df0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! This program will analyze your file to provide a word count, the top 30 words and remove the following stopwords.\n",
      "\n",
      "======================================================================================================================== \n",
      "\n",
      "[(10, 'to'), (10, 'and'), (9, 'the'), (7, 'of'), (6, 'amazon'), (6, 'access'), (4, 'web'), (4, 'this'), (4, 'storage'), (4, 'it'), (4, 'a'), (3, 'your'), (3, 'you'), (3, 'simple'), (3, 'service'), (3, 'on'), (3, 'is'), (3, 'can'), (3, 'any'), (2, 'who'), (2, 'that'), (2, 'store'), (2, 'services'), (2, 's3)'), (2, 'retrieve'), (2, 'how'), (2, 'guide'), (2, 'describes'), (2, 'control'), (2, 'benefits'), (2, 'authentication'), (2, '(amazon'), (1, 'write).'), (1, 'within'), (1, 'with'), (1, 'what'), (1, 'web.'), (1, 'web-scale'), (1, 'verifies'), (1, 'uses'), (1, 'user'), (1, 'use'), (1, 'type'), (1, 'trying'), (1, 'time,'), (1, 'those'), (1, 'summary'), (1, 'sites.'), (1, 'should'), (1, 'service.'), (1, 'send'), (1, 'section,'), (1, 'scale'), (1, 'scalable,'), (1, 'same'), (1, 's3,'), (1, 's3'), (1, 'run'), (1, 'resources.'), (1, 'requests'), (1, 'reliable,'), (1, 'reading'), (1, 'read'), (1, 'provides'), (1, 'process.'), (1, 'process'), (1, 'permissions'), (1, 'pass'), (1, 'own'), (1, 'offers'), (1, 'objects,'), (1, 'objects'), (1, 'network'), (1, 'maximize'), (1, 'manage'), (1, 'make'), (1, 'its'), (1, 'introduction'), (1, 'internet.'), (1, 'interface'), (1, 'infrastructure'), (1, 'inexpensive'), (1, 'in'), (1, 'identity'), (1, 'idea'), (1, 'highly'), (1, 'have'), (1, 'has'), (1, 'good'), (1, 'global'), (1, 'gives'), (1, 'from'), (1, 'for'), (1, 'fit'), (1, 'fast,'), (1, 'example,'), (1, 'easier.'), (1, 'developers.'), (1, 'developer'), (1, 'detailed'), (1, 'designed'), (1, 'defines'), (1, 'data,'), (1, 'data'), (1, 'create'), (1, 'computing'), (1, 'business.'), (1, 'buckets,'), (1, 'buckets'), (1, 'at'), (1, 'anywhere'), (1, 'amount'), (1, 'also'), (1, 'aims'), (1, 'after'), (1, '(for'), (1, '(aws).')]\n",
      "======================================================================================================================== \n",
      "\n",
      "Your input file has characters = 1217\n",
      "Your input file has lines = 6\n",
      "Your input file has the following words = 203\n",
      "======================================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      " The 30 most frequent words are /n\n",
      " 1.   10 to\n",
      " 2.   10 and\n",
      " 3.    9 the\n",
      " 4.    7 of\n",
      " 5.    6 amazon\n",
      " 6.    6 access\n",
      " 7.    4 web\n",
      " 8.    4 this\n",
      " 9.    4 storage\n",
      "10.    4 it\n",
      "11.    4 a\n",
      "12.    3 your\n",
      "13.    3 you\n",
      "14.    3 simple\n",
      "15.    3 service\n",
      "16.    3 on\n",
      "17.    3 is\n",
      "18.    3 can\n",
      "19.    3 any\n",
      "20.    2 who\n",
      "21.    2 that\n",
      "22.    2 store\n",
      "23.    2 services\n",
      "24.    2 s3)\n",
      "25.    2 retrieve\n",
      "26.    2 how\n",
      "27.    2 guide\n",
      "28.    2 describes\n",
      "29.    2 control\n",
      "30.    2 benefits\n",
      "================================================================================ \n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ \tThank You!\t @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "# Program assumes user has downloaded an imported stopwords from NLTK\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "freq_count('/content/drive/MyDrive/NLP/TEXT FILES/S3.txt')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNYSsh78sz82NyReviqmo4b",
   "mount_file_id": "123d2p5J8k4p-Ce4upcpIxJ_YAjmsquQs",
   "name": "PROGRAM2_2048046.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
